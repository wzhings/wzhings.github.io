[{"authors":["admin"],"categories":null,"content":" Zuhui Wang is currently a 2nd-year Ph.D. student in Computer Science at Stony Brook University (SBU), advised by Dr. Zhaozheng Yin. Zuhui received his Master degree in Computer Science at University of Central Florida in 2016, and also earned his Bachelor degree in Computer Science and Technology at Southern Medical University in 2009.\nHe is currently interested in biomedical image processing, multimodal analysis, and video representation.\nThe special link of Zuhui\u0026rsquo;s life \u0026ndash; Dr. Kexin Xiong\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1608923065,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://wzhings.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"Zuhui Wang is currently a 2nd-year Ph.D. student in Computer Science at Stony Brook University (SBU), advised by Dr. Zhaozheng Yin. Zuhui received his Master degree in Computer Science at University of Central Florida in 2016, and also earned his Bachelor degree in Computer Science and Technology at Southern Medical University in 2009.\nHe is currently interested in biomedical image processing, multimodal analysis, and video representation.\nThe special link of Zuhui\u0026rsquo;s life \u0026ndash; Dr.","tags":null,"title":"Zuhui Wang","type":"author"},{"authors":null,"categories":null,"content":"I will share my personal reading and lecture notes here.\nFeel free to contact me if you have any comment and hope you will like my notes.\n Pattern Recognition and Machine Learning (PRML)  ","date":1536465600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1557538085,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"https://wzhings.github.io/tutorial/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/","section":"tutorial","summary":"I will share my personal reading and lecture notes here.\nFeel free to contact me if you have any comment and hope you will like my notes.\n Pattern Recognition and Machine Learning (PRML)  ","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"The Best Way to Create the Website You Want from Markdown (or RStudio/Jupyter)\nBuild Anything with Widgets\nStar\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"c9eae2fa1aded3b7d7d30eb28f576cd7","permalink":"https://wzhings.github.io/other_homes/hero/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/hero/","section":"other_homes","summary":"The Best Way to Create the Website You Want from Markdown (or RStudio/Jupyter)\nBuild Anything with Widgets\nStar","tags":null,"title":"Academic","type":"other_homes"},{"authors":null,"categories":null,"content":"Null\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557518851,"objectID":"d68db0ead894c9331ce093ac2cb1f8bd","permalink":"https://wzhings.github.io/other_homes/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/posts/","section":"other_homes","summary":"Null","tags":null,"title":"Posts","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"412cd4c5482a964b5faf98d6a9561c30","permalink":"https://wzhings.github.io/other_homes/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/experience/","section":"other_homes","summary":"","tags":null,"title":"Experience","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"64b10dc2e31e031688024d18c6b3321e","permalink":"https://wzhings.github.io/other_homes/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/accomplishments/","section":"other_homes","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"b01bd430a37f382361bed713893e10ea","permalink":"https://wzhings.github.io/other_homes/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/people/","section":"other_homes","summary":"","tags":null,"title":"People","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"030b5250f0f507571d53f5a91454c0f7","permalink":"https://wzhings.github.io/other_homes/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/talks/","section":"other_homes","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"e15ebc1ab31ec34c6c0f49ddb630f8df","permalink":"https://wzhings.github.io/other_homes/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/featured/","section":"other_homes","summary":"","tags":null,"title":"Featured Publications","type":"other_homes"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556599863,"objectID":"1107d1781c4e524299b2b86f50ac9cad","permalink":"https://wzhings.github.io/other_homes/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/other_homes/tags/","section":"other_homes","summary":"","tags":null,"title":"Popular Topics","type":"other_homes"},{"authors":null,"categories":null,"content":"Under construction\u0026hellip;\n","date":1609087944,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609088488,"objectID":"dee6477f3d1f820eb7d36e2b327a0026","permalink":"https://wzhings.github.io/project/cellcounting/","publishdate":"2020-12-27T11:52:24-05:00","relpermalink":"/project/cellcounting/","section":"project","summary":"This project aims to develop an automatic algorithm to count cells in microscopy images using deep learning.","tags":["deep learning","biomedical image processing","cell counting"],"title":"Microscropy Cell Counting","type":"project"},{"authors":null,"categories":null,"content":"","date":1609087682,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609088488,"objectID":"81ace42f87f90fef5330a16b14d18f4b","permalink":"https://wzhings.github.io/project/antivaccine/","publishdate":"2020-12-27T11:48:02-05:00","relpermalink":"/project/antivaccine/","section":"project","summary":"This project focuses on building deep learning models to detect antivaccine posts on social media.","tags":["deep-learning","antivaccine","multimedia"],"title":"Detecting Medical Misinformation on Social Media","type":"project"},{"authors":["**Zuhui Wang**","Zhaozheng Yin","Young Anna Argyris"],"categories":null,"content":" Abstract In 2019, outbreaks of vaccine-preventable diseases reached the highest number in the US since 1992. Medical misinformation, such as antivaccine content propagating through social media, is associated with increases in vaccine delay and refusal. Our overall goal is to develop an automatic detector for antivaccine messages to counteract the negative impact that antivaccine messages have on the public health. Very few extant detection systems have considered multimodality of social media posts (images, texts, and hashtags), and instead focus on textual components, despite the rapid growth of photo-sharing applications (e.g., Instagram). As a result, existing systems are not sufficient for detecting antivaccine messages with heavy visual components (e.g., images) posted on these newer platforms. To solve this problem, we propose a deep learning network that leverages both visual and textual information. A new semanticand task-level attention mechanism was created to help our model to focus on the essential contents of a post that signal antivaccine messages. The proposed model, which consists of three branches, can generate comprehensive fused features for predictions. Moreover, an ensemble method is proposed to further improve the final prediction accuracy. To evaluate the proposed model’s performance, a real-world social media dataset that consists of more than 30,000 samples was collected from Instagram between January 2016 and October 2019. Our 30 experiment results demonstrate that the final network achieves above 97% testing accuracy and outperforms other relevant models, demonstrating that it can detect a large amount of antivaccine messages posted daily.\n","date":1604984400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609088488,"objectID":"e509b5bdeaa7bcecb9b1b7b7d98b01a8","permalink":"https://wzhings.github.io/publication/journals/antivaccine/","publishdate":"2020-11-10T00:00:00-05:00","relpermalink":"/publication/journals/antivaccine/","section":"publication","summary":"Abstract In 2019, outbreaks of vaccine-preventable diseases reached the highest number in the US since 1992. Medical misinformation, such as antivaccine content propagating through social media, is associated with increases in vaccine delay and refusal. Our overall goal is to develop an automatic detector for antivaccine messages to counteract the negative impact that antivaccine messages have on the public health. Very few extant detection systems have considered multimodality of social media posts (images, texts, and hashtags), and instead focus on textual components, despite the rapid growth of photo-sharing applications (e.","tags":["Deep Learning","Multimedia","Multimodal","Antivaccine"],"title":"Detecting Medical Misinformation on Social Media Using Multimodal Deep Learning","type":"publication"},{"authors":["Young Anna Argyris","**Zuhui Wang**","Yongsuk Kim","Zhaozheng Yin"],"categories":null,"content":" Abstract Influencers are non-celebrity individuals who gain popularity on social media by posting visually attractive content (e.g., photos and videos) and by interacting with other users (i.e., Followers) to create a sense of authenticity and friendship. Brands partner with Influencers to garner engagement from their target consumers in a new marketing strategy known as “Influencer marketing.” Nonetheless, the theoretical underpinnings of such remains unknown. We suggest a new conceptual framework of “Visual-Congruence-induced Social Influence (VCSI),” which contextualizes the Similarity-Attraction Model in the Social Influence literature. Using VCSI, we delineate how Influencers use visual congruence as representations of shared interests in a specific area to build strong bonds with Followers. This intimate affiliation catalyzes (i.e., mediates) the positive effects of visual congruence on Followers’ brand engagement. To test these hypotheses, we conducted in vivo observations of Influencer marketing on Instagram. We collected \u0026gt;45,000 images and social media usage behaviors over 26 months. We then applied deep-learning algorithms to automatically classify each image and used social media analytics to disclose hidden associations between visual elements and brand engagement. Our hypothesis testing results provide empirical support for VCSI, advancing theories into the rapidly growing fields of multimodal content and Influencer marketing.\n","date":1591588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609088488,"objectID":"c9e1a4433efcbab652594b23872d8ca7","permalink":"https://wzhings.github.io/publication/journals/visualcong/","publishdate":"2020-06-08T00:00:00-04:00","relpermalink":"/publication/journals/visualcong/","section":"publication","summary":"Abstract Influencers are non-celebrity individuals who gain popularity on social media by posting visually attractive content (e.g., photos and videos) and by interacting with other users (i.e., Followers) to create a sense of authenticity and friendship. Brands partner with Influencers to garner engagement from their target consumers in a new marketing strategy known as “Influencer marketing.” Nonetheless, the theoretical underpinnings of such remains unknown. We suggest a new conceptual framework of “Visual-Congruence-induced Social Influence (VCSI),” which contextualizes the Similarity-Attraction Model in the Social Influence literature.","tags":["Multimedia","Deep Learning","Computer Vision"],"title":"The effects of visual congruence on increasing consumers’ brand engagement: An empirical investigation of influencer marketing on instagram using deep-learning algorithms for automatic image classification","type":"publication"},{"authors":null,"categories":null,"content":"This chapter contains the following content:\n Eq. 1.90 Derivation  ","date":1536465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557538085,"objectID":"726b221643375a42afd35bae52f57215","permalink":"https://wzhings.github.io/tutorial/ch1_intro/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/ch1_intro/","section":"tutorial","summary":"This chapter contains the following content:\n Eq. 1.90 Derivation  ","tags":null,"title":"Ch1. INTRODUCTION","type":"docs"},{"authors":null,"categories":null,"content":" Section 1.5.5, PRML In this note, I will show the derivation procedure of the equation of 1.90 step by step. Before we start, I have to claim that the version of the textbook I am reading is the 2006 version. The Eq. 1.90 is list on Page 47.\nFrom Page 46 we know, the expected loss can be written as\n\\[\\small \\mathbb{E}[L] = \\iint\\{y(\\mathbf{x}) - t\\}^2 p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t \\]\nAnd we know\n\\[\\small \\{y(\\mathbf{x}) - t\\}^2 = \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}] + \\mathbb{E}[t|\\mathbf{x}] - t\\}^2 = \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}^2 + 2\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}\\{\\mathbb{E}[t|\\mathbf{x}] - t\\} + \\{\\mathbb{E}[t|\\mathbf{x}] - t\\}^2 \\] In the above equation,\n for the first term \\(\\small \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}^2\\), we put it back to the expected loss equation and get \\[\\small \\iint \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}^2 p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\int \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}^2 p(\\mathbf{x})\\mathrm{d}\\mathbf{x} \\] Because we know the marginal probability is \\(\\int p(\\mathbf{x}, t)\\mathrm{d}t = p(\\mathbf x)\\), and \\(\\small \\mathbb{E}[t|\\mathbf{x}] \\) is a constant when \\(\\mathbf x\\) is given.\n for the middle term, \\(\\small 2\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}\\{\\mathbb{E}[t|\\mathbf{x}] - t\\}\\), we can also put it back to the expected loss equaiton. Here we omit the constant number \u0026ndash; $\\small 2$ and get $$ \\small \\iint \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}\\{\\mathbb{E}[t|\\mathbf{x}] - t\\} p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\iint \\big( \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\} \\mathbb{E}[t|\\mathbf{x}] - \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}t\\big) p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t $$ $$ \\small = \\iint \\big( \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\} \\mathbb{E}[t|\\mathbf{x}] \\big)p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t - \\iint \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}t \\big)p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t $$ In the first term of the above equation, we know $\\small \\mathbb{E}[t|\\mathbf{x}]$ is a constant. Then, the first term can be written as: $$\\small \\iint \\big( \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\} \\mathbb{E}[t|\\mathbf{x}] \\big)p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\int \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\})\\mathbb{E}[t|\\mathbf{x}] \\}p(\\mathbf x) \\mathrm d\\mathbf x\n$$ The second term in the above equaiton can be written as (with joing probability definition $\\small p(\\mathbf x, t)$): $$ \\small \\iint \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}t \\big)p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\iint \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}t p(t|\\mathbf x)p(\\mathbf x)\\mathrm{d}\\mathbf{x}\\mathrm{d}t $$ We also know the defintion of $\\small \\mathbb E[t|\\mathbf x] = \\int t p(t|\\mathbf x) dt$, then the above equation can be written as: $$\\small \\iint \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}t \\big)p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t= \\iint \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}\\big)t p(t|\\mathbf x)p(\\mathbf x)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\int \\big(\\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\})\\mathbb{E}[t|\\mathbf{x}]p(\\mathbf x) \\mathrm d\\mathbf x $$ Then, we know the first term and second term are idetical. Therefore, the middle term of the original euqation is just $\\small 0$.\n for the last term, $\\small \\{\\mathbb{E}[t|\\mathbf{x}] - t\\}^2$ can be insert back to the expected loss euqation and get $$\\small \\iint \\{\\mathbb{E}[t|\\mathbf{x}] - t\\}^2p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\iint \\{t - \\mathbb{E}[t|\\mathbf{x}]\\}^2 p(t|\\mathbf x)p(\\mathbf x)\\mathrm dt \\mathrm d\\mathbf x $$ Here we need to use another time of Expectation definition: $$\\small \\int \\{\\mathbb{E}[t|\\mathbf{x}] - t\\}^2p(t|\\mathbf x)\\mathrm dt = \\mathbb E[\\{t - \\mathbb{E}[t|\\mathbf{x}]\\}^2|\\mathbf x] = \\mathrm{var}[t|\\mathbf x] $$ Then, the last term can be written as following: $$\\small \\iint \\{\\mathbb{E}[t|\\mathbf{x}] - t\\}^2p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t = \\iint \\{t - \\mathbb{E}[t|\\mathbf{x}]\\}^2 p(t|\\mathbf x)p(\\mathbf x)\\mathrm dt \\mathrm d\\mathbf x = \\int \\mathrm{var}[t|\\mathbf x] p(\\mathbf x) \\mathrm d\\mathbf x $$\n  Therefore, to get the expected loss equaiton of $1.90$, we can have $$\\small \\mathbb{E}[L] = \\int \\{y(\\mathbf{x}) - \\mathbb{E}[t|\\mathbf{x}]\\}^2 p(\\mathbf{x})\\mathrm{d}\\mathbf{x} + \\int \\mathrm{var}[t|\\mathbf x] p(\\mathbf x) \\mathrm d\\mathbf x $$\nBTW, for the 2006 version E-book, the last term of Eq. 1.90 has a typo. It has been fixed at page 7 in the PRML Errata File.\n-[END]-\n","date":1536465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557538085,"objectID":"b560783f04ae7021dd4cd18f09485158","permalink":"https://wzhings.github.io/tutorial/prml_ch1_eq1_90/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/prml_ch1_eq1_90/","section":"tutorial","summary":"Section 1.5.5, PRML In this note, I will show the derivation procedure of the equation of 1.90 step by step. Before we start, I have to claim that the version of the textbook I am reading is the 2006 version. The Eq. 1.90 is list on Page 47.\nFrom Page 46 we know, the expected loss can be written as\n\\[\\small \\mathbb{E}[L] = \\iint\\{y(\\mathbf{x}) - t\\}^2 p(\\mathbf{x}, t)\\mathrm{d}\\mathbf{x}\\mathrm{d}t \\]","tags":null,"title":"Equation derivation procedure for 1.90","type":"docs"},{"authors":null,"categories":null,"content":"This page contain the reading notes of Pattern Recognition and Machine Learning (PRML), 2006 Version E-book.\nIt contains the following chapters:\n Introduction  ","date":1536465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557538085,"objectID":"7a018a70a3d3208a8138685b329f33e5","permalink":"https://wzhings.github.io/tutorial/prml/","publishdate":"2018-09-09T00:00:00-04:00","relpermalink":"/tutorial/prml/","section":"tutorial","summary":"This page contain the reading notes of Pattern Recognition and Machine Learning (PRML), 2006 Version E-book.\nIt contains the following chapters:\n Introduction  ","tags":null,"title":"Pattern Recognition and Machine Learning","type":"docs"}]