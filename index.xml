<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Zuhui Wang&#39;s Homepage</title>
    <link>https://wzhings.github.io/</link>
    <description>Recent content on Zuhui Wang&#39;s Homepage</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy;{year} Zuhui Wang</copyright>
    <lastBuildDate>Sun, 27 Dec 2020 12:18:52 -0500</lastBuildDate>
    
	    <atom:link href="https://wzhings.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Academic</title>
      <link>https://wzhings.github.io/other_homes/hero/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/hero/</guid>
      <description>&lt;p&gt;&lt;strong&gt;The Best Way to Create the Website You Want from Markdown (or RStudio/Jupyter)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Build &lt;strong&gt;Anything&lt;/strong&gt; with Widgets&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;text-shadow: none;&#34;&gt;&lt;a class=&#34;github-button&#34; href=&#34;https://github.com/gcushen/hugo-academic&#34; data-icon=&#34;octicon-star&#34; data-size=&#34;large&#34; data-show-count=&#34;true&#34; aria-label=&#34;Star this on GitHub&#34;&gt;Star&lt;/a&gt;&lt;script async defer src=&#34;https://buttons.github.io/buttons.js&#34;&gt;&lt;/script&gt;&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posts</title>
      <link>https://wzhings.github.io/other_homes/posts/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/posts/</guid>
      <description>&lt;p&gt;Null&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>https://wzhings.github.io/other_homes/experience/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accomplish&amp;shy;ments</title>
      <link>https://wzhings.github.io/other_homes/accomplishments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/accomplishments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://wzhings.github.io/other_homes/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent &amp; Upcoming Talks</title>
      <link>https://wzhings.github.io/other_homes/talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/talks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Featured Publications</title>
      <link>https://wzhings.github.io/other_homes/featured/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/featured/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Popular Topics</title>
      <link>https://wzhings.github.io/other_homes/tags/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://wzhings.github.io/other_homes/tags/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cat</title>
      <link>https://wzhings.github.io/cat/</link>
      <pubDate>Sun, 27 Dec 2020 12:18:52 -0500</pubDate>
      
      <guid>https://wzhings.github.io/cat/</guid>
      <description>&lt;p&gt;Hello friends, here is my cat, Mour-mour (ÂìûÂìû). Mour is a one-year-old, lively boy. I am so happy to live with him as his father, and we both love his mom üë™. Here are some pictures of him. Please enjoy them!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;[2020-11-30] Mour-mour is sleeping on my table.
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m1-20201130.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[2020-11-22] Mour-mour is lying down on my desk (just finish eating his favorite turkey snack).
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m2-20201122.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[2020-11-16] Mour-mour is lying down on my bed after playing his cat feather teaser.
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m3-20201116.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[2020-09-26] Mour-mour is sleeping beside me with his hands up.
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m4-20200926.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[2020-06-18] Mour-mour is lying down with his friend, Goo-mi.
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m5-20200618.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[2020-05-13] Mour-mour wants to play with me&amp;hellip;when I am busy.
&lt;img class=‚Äúspecial-img-class‚Äù style=&#34;width:10% height:10%&#34; src=&#34;https://wzhings.github.io/img/m6-20200513.jpg&#34; alt=&#34;peace dove&#34; title=&#34;mour is sleeping on my table&#34;/&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Microscropy Cell Counting</title>
      <link>https://wzhings.github.io/project/cellcounting/</link>
      <pubDate>Sun, 27 Dec 2020 11:52:24 -0500</pubDate>
      
      <guid>https://wzhings.github.io/project/cellcounting/</guid>
      <description>&lt;p&gt;Under construction&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Medical Misinformation on Social Media</title>
      <link>https://wzhings.github.io/project/antivaccine/</link>
      <pubDate>Sun, 27 Dec 2020 11:48:02 -0500</pubDate>
      
      <guid>https://wzhings.github.io/project/antivaccine/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Detecting Medical Misinformation on Social Media Using Multimodal Deep Learning</title>
      <link>https://wzhings.github.io/publication/journals/antivaccine/</link>
      <pubDate>Tue, 10 Nov 2020 00:00:00 -0500</pubDate>
      
      <guid>https://wzhings.github.io/publication/journals/antivaccine/</guid>
      <description>

&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;In 2019, outbreaks of vaccine-preventable diseases reached the highest number in the US since 1992. Medical misinformation, such as antivaccine content propagating through social media, is associated with increases in vaccine delay and refusal. Our overall goal is to develop an automatic detector for antivaccine messages to counteract the negative impact that antivaccine messages have on the public health. Very few extant detection systems have considered multimodality of social media posts (images, texts, and hashtags), and instead focus on
textual components, despite the rapid growth of photo-sharing applications (e.g., Instagram). As a result, existing systems are not sufficient for detecting antivaccine messages with heavy visual components (e.g., images) posted on these newer platforms. To solve this problem, we propose a deep learning network that leverages both visual and textual information. A new semanticand task-level attention mechanism was created to help our model to focus on the essential contents of a post that signal antivaccine messages. The proposed model, which consists of three branches, can generate comprehensive fused features for predictions. Moreover, an ensemble method is proposed to further improve the final prediction accuracy. To evaluate the proposed model‚Äôs performance, a real-world social media dataset that consists of more than 30,000 samples was collected from Instagram between January 2016 and October 2019. Our 30 experiment results demonstrate that the final network achieves above 97% testing accuracy and outperforms other relevant models, demonstrating that it can detect a large amount of antivaccine messages posted daily.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The effects of visual congruence on increasing consumers‚Äô brand engagement: An empirical investigation of influencer marketing on instagram using deep-learning algorithms for automatic image classification</title>
      <link>https://wzhings.github.io/publication/journals/visualcong/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 -0400</pubDate>
      
      <guid>https://wzhings.github.io/publication/journals/visualcong/</guid>
      <description>

&lt;h3 id=&#34;abstract&#34;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;Influencers are non-celebrity individuals who gain popularity on social media by posting visually attractive content (e.g., photos and videos) and by interacting with other users (i.e., Followers) to create a sense of authenticity and friendship. Brands partner with Influencers to garner engagement from their target consumers in a new marketing strategy known as ‚ÄúInfluencer marketing.‚Äù Nonetheless, the theoretical underpinnings of such remains unknown. We suggest a new conceptual framework of ‚ÄúVisual-Congruence-induced Social Influence (VCSI),‚Äù which contextualizes the Similarity-Attraction Model in the Social Influence literature. Using VCSI, we delineate how Influencers use visual congruence as representations of shared interests in a specific area to build strong bonds with Followers. This intimate affiliation catalyzes (i.e., mediates) the positive effects of visual congruence on Followers‚Äô brand engagement. To test these hypotheses, we conducted in vivo observations of Influencer marketing on Instagram. We collected &amp;gt;45,000 images and social media usage behaviors over 26 months. We then applied deep-learning algorithms to automatically classify each image and used social media analytics to disclose hidden associations between visual elements and brand engagement. Our hypothesis testing results provide empirical support for VCSI, advancing theories into the rapidly growing fields of multimodal content and Influencer marketing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ch1. INTRODUCTION</title>
      <link>https://wzhings.github.io/tutorial/ch1_intro/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>https://wzhings.github.io/tutorial/ch1_intro/</guid>
      <description>&lt;p&gt;This chapter contains the following content:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wzhings.github.io/tutorial/prml_ch1_eq1_90/&#34;&gt;Eq. 1.90 Derivation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Equation derivation procedure for 1.90</title>
      <link>https://wzhings.github.io/tutorial/prml_ch1_eq1_90/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>https://wzhings.github.io/tutorial/prml_ch1_eq1_90/</guid>
      <description>

&lt;!--
inline \\(a^2 + b^2 = c\\)
block: \\[ \\]
--&gt;

&lt;h2 id=&#34;section-1-5-5-prml&#34;&gt;Section 1.5.5, &lt;strong&gt;&lt;em&gt;PRML&lt;/em&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In this note, I will show the derivation procedure of the equation of 1.90 step by step. Before we start, I have to claim that the version of the textbook I am reading is the 2006 version. The Eq. 1.90 is list on Page 47.&lt;/p&gt;

&lt;p&gt;From Page 46 we know, the expected loss can be written as&lt;/p&gt;

&lt;p&gt;\[\small
\mathbb{E}[L] = \iint\{y(\mathbf{x}) - t\}^2 p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t
\]&lt;/p&gt;

&lt;p&gt;And we know&lt;/p&gt;

&lt;p&gt;\[\small
\{y(\mathbf{x}) - t\}^2 = \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}] + \mathbb{E}[t|\mathbf{x}] - t\}^2 = \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}^2 + 2\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\{\mathbb{E}[t|\mathbf{x}] - t\} + \{\mathbb{E}[t|\mathbf{x}] - t\}^2
\]
In the above equation,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;for the first term \(\small \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}^2\), we put it back to the expected loss equation and get
\[\small
\iint \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}^2 p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \int \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}^2 p(\mathbf{x})\mathrm{d}\mathbf{x}
\]
Because we know the marginal probability is \(\int p(\mathbf{x}, t)\mathrm{d}t = p(\mathbf x)\), and \(\small \mathbb{E}[t|\mathbf{x}] \) is a &lt;em&gt;constant&lt;/em&gt; when \(\mathbf x\) is given.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;for the middle term, \(\small 2\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\{\mathbb{E}[t|\mathbf{x}] - t\}\), we can also put it back to the expected loss equaiton. Here we omit the constant number &amp;ndash; $\small 2$ and get
$$ \small
\iint \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\{\mathbb{E}[t|\mathbf{x}] - t\} p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \iint \big( \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\} \mathbb{E}[t|\mathbf{x}] - \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}t\big) p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t $$
$$ \small
= \iint \big( \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\} \mathbb{E}[t|\mathbf{x}] \big)p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t - \iint \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}t \big)p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t
$$
In the first term of the above equation, we know $\small \mathbb{E}[t|\mathbf{x}]$ is a constant. Then, the &lt;strong&gt;&lt;em&gt;first term&lt;/em&gt;&lt;/strong&gt; can be written as:
$$\small
\iint \big( \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\} \mathbb{E}[t|\mathbf{x}] \big)p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \int \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\})\mathbb{E}[t|\mathbf{x}] \}p(\mathbf x) \mathrm d\mathbf x&lt;br /&gt;
$$
The &lt;strong&gt;&lt;em&gt;second term&lt;/em&gt;&lt;/strong&gt; in the above equaiton can be written as (with joing probability definition $\small p(\mathbf x, t)$):
$$ \small
\iint \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}t \big)p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \iint \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}t p(t|\mathbf x)p(\mathbf x)\mathrm{d}\mathbf{x}\mathrm{d}t
$$
We also know the defintion of $\small \mathbb E[t|\mathbf x] = \int t p(t|\mathbf x) dt$, then the above equation can be written as:
$$\small
\iint \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}t \big)p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t= \iint \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\big)t p(t|\mathbf x)p(\mathbf x)\mathrm{d}\mathbf{x}\mathrm{d}t = \int \big(\{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\})\mathbb{E}[t|\mathbf{x}]p(\mathbf x) \mathrm d\mathbf x
$$
Then, we know the &lt;strong&gt;&lt;em&gt;first term&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;second term&lt;/em&gt;&lt;/strong&gt; are idetical. Therefore, the middle term of the original euqation is just $\small 0$.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;for the last term, $\small \{\mathbb{E}[t|\mathbf{x}] - t\}^2$ can be insert back to the expected loss euqation and get
$$\small
\iint \{\mathbb{E}[t|\mathbf{x}] - t\}^2p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \iint \{t - \mathbb{E}[t|\mathbf{x}]\}^2 p(t|\mathbf x)p(\mathbf x)\mathrm dt \mathrm d\mathbf x
$$
Here we need to use another time of &lt;em&gt;Expectation&lt;/em&gt; definition:
$$\small
\int \{\mathbb{E}[t|\mathbf{x}] - t\}^2p(t|\mathbf x)\mathrm dt = \mathbb E[\{t - \mathbb{E}[t|\mathbf{x}]\}^2|\mathbf x] = \mathrm{var}[t|\mathbf x]
$$
Then, the last term can be written as following:
$$\small
\iint \{\mathbb{E}[t|\mathbf{x}] - t\}^2p(\mathbf{x}, t)\mathrm{d}\mathbf{x}\mathrm{d}t = \iint \{t - \mathbb{E}[t|\mathbf{x}]\}^2 p(t|\mathbf x)p(\mathbf x)\mathrm dt \mathrm d\mathbf x = \int \mathrm{var}[t|\mathbf x] p(\mathbf x) \mathrm d\mathbf x
$$&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Therefore, to get the expected loss equaiton of $1.90$, we can have
$$\small
\mathbb{E}[L] = \int \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}^2 p(\mathbf{x})\mathrm{d}\mathbf{x} +  \int \mathrm{var}[t|\mathbf x] p(\mathbf x) \mathrm d\mathbf x
$$&lt;/p&gt;

&lt;p&gt;BTW, for the 2006 version E-book, the last term of Eq. 1.90 has a typo. It has been fixed at page 7 in the &lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/prml-errata-1st-20110921.pdf&#34; target=&#34;_blank&#34;&gt;PRML Errata File&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;-[&lt;strong&gt;END&lt;/strong&gt;]-&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pattern Recognition and Machine Learning</title>
      <link>https://wzhings.github.io/tutorial/prml/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>https://wzhings.github.io/tutorial/prml/</guid>
      <description>&lt;p&gt;This page contain the reading notes of Pattern Recognition and Machine Learning (&lt;strong&gt;PRML&lt;/strong&gt;), 2006 Version E-book.&lt;/p&gt;

&lt;p&gt;It contains the following chapters:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://wzhings.github.io/tutorial/ch1_intro/&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
